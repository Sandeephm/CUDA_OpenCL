{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenCL_Python.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNVEBZ7/SPsJMWkfiigL0zn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sandeephm/CUDA_OpenCL/blob/master/OpenCL_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNvgJz7gI2kK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "82e3108c-419b-4b37-8e3f-5bc5f0113fa3"
      },
      "source": [
        "!pip install pyopencl"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyopencl in /usr/local/lib/python3.6/dist-packages (2020.2.1)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from pyopencl) (1.4.4)\n",
            "Requirement already satisfied: pytools>=2017.6 in /usr/local/lib/python3.6/dist-packages (from pyopencl) (2020.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pyopencl) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pyopencl) (1.18.5)\n",
            "Requirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pyopencl) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc1PbC0fJRXF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1fdfe4cc-e69e-44ec-db02-26421f13d8b5"
      },
      "source": [
        "from __future__ import absolute_import, print_function\n",
        "import numpy as np\n",
        "import pyopencl as cl\n",
        "\n",
        "a_np = np.random.rand(50000).astype(np.float32)\n",
        "b_np = np.random.rand(50000).astype(np.float32)\n",
        "\n",
        "# Create a context\n",
        "ctx = cl.create_some_context()\n",
        "# Create a command queue\n",
        "queue = cl.CommandQueue(ctx)\n",
        "\n",
        "mf = cl.mem_flags\n",
        "a_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=a_np)\n",
        "b_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=b_np)\n",
        "\n",
        "#Create program Object\n",
        "prg = cl.Program(ctx, \"\"\"\n",
        "__kernel void sum(\n",
        "    __global const float *a_g, __global const float *b_g, __global float *res_g)\n",
        "{\n",
        "  int gid = get_global_id(0);\n",
        "  res_g[gid] = a_g[gid] + b_g[gid];\n",
        "}\n",
        "\"\"\").build()\n",
        "\n",
        "res_g = cl.Buffer(ctx, mf.WRITE_ONLY, a_np.nbytes)\n",
        "prg.sum(queue, a_np.shape, None, a_g, b_g, res_g)\n",
        "\n",
        "res_np = np.empty_like(a_np)\n",
        "cl.enqueue_copy(queue, res_np, res_g)\n",
        "\n",
        "# Check on CPU with Numpy:\n",
        "print(res_np - (a_np + b_np))\n",
        "print(np.linalg.norm(res_np - (a_np + b_np)))\n",
        "assert np.allclose(res_np, a_np + b_np)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. ... 0. 0. 0.]\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDyOTnJzK0Bv",
        "colab_type": "text"
      },
      "source": [
        "#Hands on OpenCL "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDSEvBxyK4Qd",
        "colab_type": "text"
      },
      "source": [
        "Device Info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xuYTT5gK3-s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "d8f14354-32db-42a8-f056-82a99afb5f53"
      },
      "source": [
        "#\n",
        "# Display Device Information\n",
        "#\n",
        "# Script to print out some information about the OpenCL devices\n",
        "# and platforms available on your system\n",
        "#\n",
        "# History: C++ version written by Tom Deakin, 2012\n",
        "#          Ported to Python by Tom Deakin, July 2013\n",
        "#\n",
        "\n",
        "# Import the Python OpenCL API\n",
        "import pyopencl as cl\n",
        "\n",
        "# Create a list of all the platform IDs\n",
        "platforms = cl.get_platforms()\n",
        "\n",
        "print(\"\\nNumber of OpenCL platforms:\", len(platforms))\n",
        "\n",
        "print(\"\\n-------------------------\") \n",
        "\n",
        "# Investigate each platform\n",
        "for p in platforms:\n",
        "    # Print out some information about the platforms\n",
        "    print(\"Platform:\", p.name)\n",
        "    print(\"Vendor:\", p.vendor)\n",
        "    print(\"Version:\", p.version)\n",
        "\n",
        "    # Discover all devices\n",
        "    devices = p.get_devices()\n",
        "    print(\"Number of devices:\", len(devices))\n",
        "\n",
        "    # Investigate each device\n",
        "    for d in devices:\n",
        "        print(\"\\t-------------------------\")\n",
        "        # Print out some information about the devices\n",
        "        print(\"\\t\\tName:\", d.name)\n",
        "        print(\"\\t\\tVersion:\", d.opencl_c_version)\n",
        "        print(\"\\t\\tMax. Compute Units:\", d.max_compute_units)\n",
        "        print(\"\\t\\tLocal Memory Size:\", d.local_mem_size/1024, \"KB\")\n",
        "        print(\"\\t\\tGlobal Memory Size:\", d.global_mem_size/(1024*1024), \"MB\")\n",
        "        print(\"\\t\\tMax Alloc Size:\", d.max_mem_alloc_size/(1024*1024), \"MB\")\n",
        "        print(\"\\t\\tMax Work-group Total Size:\", d.max_work_group_size)\n",
        "\n",
        "        # Find the maximum dimensions of the work-groups\n",
        "        dim = d.max_work_item_sizes\n",
        "        print(\"\\t\\tMax Work-group Dims:(\", dim[0], \" \".join(map(str, dim[1:])), \")\")\n",
        "\n",
        "        print(\"\\t-------------------------\")\n",
        "\n",
        "    print(\"\\n-------------------------\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Number of OpenCL platforms: 1\n",
            "\n",
            "-------------------------\n",
            "Platform: NVIDIA CUDA\n",
            "Vendor: NVIDIA Corporation\n",
            "Version: OpenCL 1.2 CUDA 10.1.152\n",
            "Number of devices: 1\n",
            "\t-------------------------\n",
            "\t\tName: Tesla T4\n",
            "\t\tVersion: OpenCL C 1.2 \n",
            "\t\tMax. Compute Units: 40\n",
            "\t\tLocal Memory Size: 48.0 KB\n",
            "\t\tGlobal Memory Size: 15079.75 MB\n",
            "\t\tMax Alloc Size: 3769.9375 MB\n",
            "\t\tMax Work-group Total Size: 1024\n",
            "\t\tMax Work-group Dims:( 1024 1024 64 )\n",
            "\t-------------------------\n",
            "\n",
            "-------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip0bDtACL9Kz",
        "colab_type": "text"
      },
      "source": [
        "An OpenCL code to add"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkFklj58L88e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fc0d1bbc-d1d0-4d05-c73e-760eb2ada0b1"
      },
      "source": [
        "#\n",
        "# Vadd\n",
        "#\n",
        "# Element wise addition of two vectors (c = a + b)\n",
        "# Asks the user to select a device at runtime\n",
        "#\n",
        "# History: C version written by Tim Mattson, December 2009\n",
        "#          C version Updated by Tom Deakin and Simon McIntosh-Smith, October 2012\n",
        "#          Ported to Python by Tom Deakin, July 2013\n",
        "#\n",
        "\n",
        "# Import the Python OpenCL API\n",
        "import pyopencl as cl\n",
        "# Import the Python Maths Library (for vectors)\n",
        "import numpy\n",
        "\n",
        "# Import Standard Library to time the execution\n",
        "from time import time\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "# tolerance used in floating point comparisons\n",
        "TOL = 0.001\n",
        "# length of vectors a, b and c\n",
        "LENGTH = 1024\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "#\n",
        "# Kernel: vadd\n",
        "#\n",
        "# To compute the elementwise sum c = a + b\n",
        "#\n",
        "# Input: a and b float vectors of length count\n",
        "# Output c float vector of length count holding the sum a + b\n",
        "\n",
        "kernelsource = \"\"\"\n",
        "__kernel void vadd(\n",
        "    __global float* a,\n",
        "    __global float* b,\n",
        "    __global float* c,\n",
        "    const unsigned int count)\n",
        "{\n",
        "    int i = get_global_id(0);\n",
        "    if (i < count)\n",
        "        c[i] = a[i] + b[i];\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "# Main procedure\n",
        "\n",
        "# Create a compute context\n",
        "# Ask the user to select a platform/device on the CLI\n",
        "context = cl.create_some_context()\n",
        "\n",
        "# Create a command queue\n",
        "queue = cl.CommandQueue(context)\n",
        "\n",
        "# Create the compute program from the source buffer\n",
        "# and build it\n",
        "program = cl.Program(context, kernelsource).build()\n",
        "\n",
        "# Create a and b vectors and fill with random float values\n",
        "h_a = numpy.random.rand(LENGTH).astype(numpy.float32)\n",
        "h_b = numpy.random.rand(LENGTH).astype(numpy.float32)\n",
        "# Create an empty c vector (a+b) to be returned from the compute device\n",
        "h_c = numpy.empty(LENGTH).astype(numpy.float32)\n",
        "\n",
        "# Create the input (a, b) arrays in device memory and copy data from host\n",
        "d_a = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_a)\n",
        "d_b = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_b)\n",
        "# Create the output (c) array in device memory\n",
        "d_c = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_c.nbytes)\n",
        "\n",
        "# Start the timer\n",
        "rtime = time()\n",
        "\n",
        "# Execute the kernel over the entire range of our 1d input\n",
        "# allowing OpenCL runtime to select the work group items for the device\n",
        "vadd = program.vadd\n",
        "vadd.set_scalar_arg_dtypes([None, None, None, numpy.uint32])\n",
        "vadd(queue, h_a.shape, None, d_a, d_b, d_c, LENGTH)\n",
        "\n",
        "# Wait for the commands to finish before reading back\n",
        "queue.finish()\n",
        "rtime = time() - rtime\n",
        "print(\"The kernel ran in\", rtime, \"seconds\")\n",
        "\n",
        "# Read back the results from the compute device\n",
        "cl.enqueue_copy(queue, h_c, d_c)\n",
        "\n",
        "# Test the results\n",
        "correct = 0;\n",
        "for a, b, c in zip(h_a, h_b, h_c):\n",
        "    # assign element i of a+b to tmp\n",
        "    tmp = a + b\n",
        "    # compute the deviation of expected and output result\n",
        "    tmp -= c\n",
        "    # correct if square deviation is less than tolerance squared\n",
        "    if tmp*tmp < TOL*TOL:\n",
        "        correct += 1\n",
        "    else:\n",
        "        print(\"tmp\", tmp, \"h_a\", a, \"h_b\", b, \"h_c\", c)\n",
        "\n",
        "# Summarize results\n",
        "print(\"C = A+B:\", correct, \"out of\", LENGTH, \"results were correct.\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The kernel ran in 0.0008358955383300781 seconds\n",
            "C = A+B: 1024 out of 1024 results were correct.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cm-48FkQTdj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eab75923-c01c-4b12-a442-aed4b66a4e18"
      },
      "source": [
        "#\n",
        "# Vadd\n",
        "#\n",
        "# Element wise addition of two vectors at a time in a chain (C=A+B; D=C+E; F=D+G)\n",
        "# Asks the user to select a device at runtime\n",
        "#\n",
        "# History: Initial version based on vadd.c, written by Tim Mattson, June 2011\n",
        "#          Ported to C++ Wrapper API by Benedict Gaster, September 2011\n",
        "#          Updated to C++ Wrapper API v1.2 by Tom Deakin and Simon McIntosh-Smith, October 2012\n",
        "#          Ported to Python by Tom Deakin, July 2013\n",
        "#\n",
        "\n",
        "# Import the Python OpenCL API\n",
        "import pyopencl as cl\n",
        "# Import the Python Maths Library (for vectors)\n",
        "import numpy\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "# tolerance used in floating point comparisons\n",
        "TOL = 0.001\n",
        "# length of vectors a, b and c\n",
        "LENGTH = 1024\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "#\n",
        "# Kernel: vadd\n",
        "#\n",
        "# To compute the elementwise sum c = a + b\n",
        "#\n",
        "# Input: a and b float vectors of length count\n",
        "# Output c float vector of length count holding the sum a + b\n",
        "\n",
        "kernelsource = \"\"\"\n",
        "__kernel void vadd(\n",
        "    __global float* a,\n",
        "    __global float* b,\n",
        "    __global float* c,\n",
        "    const unsigned int count)\n",
        "{\n",
        "    int i = get_global_id(0);\n",
        "    if (i < count)\n",
        "        c[i] = a[i] + b[i];\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "# Main procedure\n",
        "\n",
        "# Create a compute context\n",
        "# Ask the user to select a platform/device on the CLI\n",
        "context = cl.create_some_context()\n",
        "\n",
        "# Create a command queue\n",
        "queue = cl.CommandQueue(context)\n",
        "\n",
        "# Create the compute program from the source buffer\n",
        "# and build it\n",
        "program = cl.Program(context, kernelsource).build()\n",
        "\n",
        "# Create a, b, e and g vectors and fill with random float values\n",
        "# Create empty vectors for c, d and f\n",
        "h_a = numpy.random.rand(LENGTH).astype(numpy.float32)\n",
        "h_b = numpy.random.rand(LENGTH).astype(numpy.float32)\n",
        "h_c = numpy.empty(LENGTH).astype(numpy.float32)\n",
        "h_d = numpy.empty(LENGTH).astype(numpy.float32)\n",
        "h_e = numpy.random.rand(LENGTH).astype(numpy.float32)\n",
        "h_f = numpy.empty(LENGTH).astype(numpy.float32)\n",
        "h_g = numpy.random.rand(LENGTH).astype(numpy.float32)\n",
        "\n",
        "# Create the input (a, b, e, g) arrays in device memory and copy data from host\n",
        "d_a = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_a)\n",
        "d_b = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_b)\n",
        "d_e = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_e)\n",
        "d_g = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_g)\n",
        "# Create the output (c, d, f) array in device memory\n",
        "d_c = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_c.nbytes)\n",
        "d_d = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_d.nbytes)\n",
        "d_f = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_f.nbytes)\n",
        "\n",
        "vadd = program.vadd\n",
        "vadd.set_scalar_arg_dtypes([None, None, None, numpy.uint32])\n",
        "\n",
        "# Execute the kernel over the entire range of our 1d input\n",
        "# allowing OpenCL runtime to select the work group items for the device\n",
        "vadd(queue, h_a.shape, None, d_a, d_b, d_c, LENGTH)\n",
        "\n",
        "# Enqueue the kernel again, but with different arguments\n",
        "vadd(queue, h_e.shape, None, d_e, d_c, d_d, LENGTH)\n",
        "\n",
        "# Enqueue the kernel a third time, again with different arguments\n",
        "vadd(queue, h_g.shape, None, d_g, d_d, d_f, LENGTH)\n",
        "\n",
        "\n",
        "# Read back the results from the compute device\n",
        "cl.enqueue_copy(queue, h_f, d_f)\n",
        "\n",
        "# Test the results\n",
        "correct = 0;\n",
        "for a, b, e, f, g in zip(h_a, h_b, h_e, h_f, h_g):\n",
        "    tmp = a + b + e + g\n",
        "    # compute the deviation of expected and output result\n",
        "    tmp -= f\n",
        "    # correct if square deviation is less than tolerance squared\n",
        "    if tmp*tmp < TOL*TOL:\n",
        "        correct += 1\n",
        "    else:\n",
        "        print(\"tmp\", tmp, \"h_a\", a, \"h_b\", b, \"h_e\", e, \"h_g\", g, \"h_f\", f)\n",
        "\n",
        "# Summarize results\n",
        "print(\"3 vector adds to find F = A+B+E+G:\", correct, \"out of\", LENGTH, \"results were correct.\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 vector adds to find F = A+B+E+G: 1024 out of 1024 results were correct.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nktRrvtiMgZ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "73e99fd4-42bf-4844-da72-d2da75e0892b"
      },
      "source": [
        "#\n",
        "# Matrix Multiplication Driver\n",
        "#\n",
        "# This is a driver program to test various ways of computing\n",
        "# the product:\n",
        "#                 C = A * B\n",
        "#\n",
        "# A and B are constant matrices, square and the order is\n",
        "# set as a constant, ORDER (see definitions.py). This is so\n",
        "# we can make a quick test of the multiplication result.\n",
        "#\n",
        "# History:   C++ version written by Tim Mattson, August 2010\n",
        "#            Modified by Simon McIntosh-Smith, September 2011\n",
        "#            Modified by Tom Deakin and Simon McIntosh-Smith, October 2012\n",
        "#            Ported to Python by Tom Deakin, July 2013\n",
        "#            Modified to assume square matrices by Ben Elgar, November 2014\n",
        "#\n",
        "\n",
        "import pyopencl as cl\n",
        "import numpy\n",
        "from time import time\n",
        "\n",
        "# Order of the square matrices A, B and C\n",
        "ORDER = 128\n",
        "\n",
        "# A elemetns are constant and equal to AVAL\n",
        "AVAL = 3.0\n",
        "\n",
        "# B elemetns are constant and equal to BVAL\n",
        "BVAL = 5.0\n",
        "\n",
        "# tolerance used in floating point comparisons\n",
        "TOL = 0.001\n",
        "\n",
        "# Max dim for NDRange\n",
        "DIM = 2\n",
        "\n",
        "# number of times to do each multiplication\n",
        "COUNT = 1\n",
        "\n",
        "#  Function to compute the matrix product (sequential algorithm, dot prod)\n",
        "def seq_mat_mul_sdot(N, A, B, C):\n",
        "    for i in range(N):\n",
        "        for j in range(N):\n",
        "            tmp = 0.0\n",
        "            for k in range(N):\n",
        "                tmp += A[i*N+k] * B[k*N+j]\n",
        "            C[i*N+j] = tmp\n",
        "\n",
        "#  Function to compute errors of the product matrix\n",
        "def error(N, C):\n",
        "   cval = float(N) * AVAL * BVAL\n",
        "   errsq = 0.0\n",
        "   for i in range(N):\n",
        "       for j in range(N):\n",
        "            err = C[i*N+j] - cval\n",
        "            errsq += err * err\n",
        "   return errsq;\n",
        "\n",
        "\n",
        "# Function to analyze and output results\n",
        "def results(N, C, run_time):\n",
        "    mflops = 2.0 * N * N * N/(1000000.0* run_time)\n",
        "    print(run_time, \"seconds at\", mflops, \"MFLOPS\")\n",
        "    errsq = error(N, C)\n",
        "    if (errsq > TOL):\n",
        "        print(\"Errors in multiplication:\", errsq)\n",
        "\n",
        "C_elem_KernelSource = '''\n",
        "__kernel void mmul(\n",
        "    const int N,\n",
        "    __global float* A,\n",
        "    __global float* B,\n",
        "    __global float* C)\n",
        "{\n",
        "    int k;\n",
        "    int i = get_global_id(0);\n",
        "    int j = get_global_id(1);\n",
        "    float tmp = 0;\n",
        "    if ((i < N) && (j < N))\n",
        "    {\n",
        "        tmp = 0.0f;\n",
        "        for (k=0; k<N; k++)\n",
        "        {\n",
        "            tmp += A[i*N + k] * B[k*N + j];\n",
        "        }\n",
        "        C[i*N + j] = tmp;\n",
        "    }\n",
        "}\n",
        "'''\n",
        "\n",
        "# A[N][N], B[N][N], C[N][N]\n",
        "N = ORDER;\n",
        "\n",
        "# Number of elements in the matrix\n",
        "size = N * N\n",
        "\n",
        "\n",
        "# A matrix\n",
        "h_A = numpy.empty(size).astype(numpy.float32)\n",
        "h_A.fill(AVAL)\n",
        "\n",
        "# B matrix\n",
        "h_B = numpy.empty(size).astype(numpy.float32)\n",
        "h_B.fill(BVAL)\n",
        "\n",
        "# C matrix\n",
        "h_C = numpy.empty(size).astype(numpy.float32)\n",
        "\n",
        "print(\"\\n===== Sequential, matrix mult (dot prod), order\", ORDER, \"on host CPU ======\\n\")\n",
        "\n",
        "for i in range(COUNT):\n",
        "    h_C.fill(0.0)\n",
        "    start_time = time()\n",
        "\n",
        "    print(\"Skipping as this takes a long time to run!\")\n",
        "    seq_mat_mul_sdot(N, h_A, h_B, h_C)\n",
        "\n",
        "    run_time = time() - start_time\n",
        "    results(N, h_C, run_time)\n",
        "\n",
        "\n",
        "# Set up OpenCL\n",
        "context = cl.create_some_context()\n",
        "queue = cl.CommandQueue(context)\n",
        "\n",
        "# Reset host buffers - just to play it safe\n",
        "h_A = numpy.empty(size).astype(numpy.float32)\n",
        "h_A.fill(AVAL)\n",
        "h_B = numpy.empty(size).astype(numpy.float32)\n",
        "h_B.fill(BVAL)\n",
        "h_C = numpy.empty(size).astype(numpy.float32)\n",
        "\n",
        "# Create OpenCL buffers\n",
        "d_a = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_A)\n",
        "d_b = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_B)\n",
        "d_c = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_C.nbytes)\n",
        "\n",
        "program = cl.Program(context, C_elem_KernelSource).build()\n",
        "mmul = program.mmul\n",
        "mmul.set_scalar_arg_dtypes([numpy.int32, None, None, None])\n",
        "\n",
        "print(\"\\n===== OpenCL, matrix mult, C(i,j) per work item, order\", N, \"======\\n\")\n",
        "\n",
        "# Do the multiplication COUNT times\n",
        "for i in range(COUNT):\n",
        "    h_C.fill(0.0)\n",
        "    start_time = time()\n",
        "\n",
        "    globalrange = (N, N)\n",
        "    localrange = None\n",
        "\n",
        "    mmul(queue, globalrange, localrange, N, d_a, d_b, d_c)\n",
        "    queue.finish()\n",
        "\n",
        "    run_time = time() - start_time\n",
        "\n",
        "    cl.enqueue_copy(queue, h_C, d_c)\n",
        "    results(N, h_C, run_time)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "===== Sequential, matrix mult (dot prod), order 128 on host CPU ======\n",
            "\n",
            "Skipping as this takes a long time to run!\n",
            "1.316636562347412 seconds at 3.185620177919134 MFLOPS\n",
            "\n",
            "===== OpenCL, matrix mult, C(i,j) per work item, order 128 ======\n",
            "\n",
            "0.0006034374237060547 seconds at 6950.685912451995 MFLOPS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Jfsk0BsOeCI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "7af373d4-566c-4650-a812-5ddc7cc9b8c3"
      },
      "source": [
        "#\n",
        "# Matrix Multiplication Driver\n",
        "#\n",
        "# This is a driver program to test various ways of computing\n",
        "# the product:\n",
        "#                 C = A * B\n",
        "#\n",
        "# A and B are constant matrices, square and the order is\n",
        "# set as a constant, ORDER (see definitions.py). This is so\n",
        "# we can make a quick test of the multiplication result.\n",
        "#\n",
        "# History:   C++ version written by Tim Mattson, August 2010\n",
        "#            Modified by Simon McIntosh-Smith, September 2011\n",
        "#            Modified by Tom Deakin and Simon McIntosh-Smith, October 2012\n",
        "#            Ported to Python by Tom Deakin, July 2013\n",
        "#            Modified to assume square matrices by Ben Elgar, November 2014\n",
        "#\n",
        "\n",
        "import pyopencl as cl\n",
        "import numpy\n",
        "from time import time\n",
        "\n",
        "# Order of the square matrices A, B and C\n",
        "ORDER = 1024\n",
        "\n",
        "# A elemetns are constant and equal to AVAL\n",
        "AVAL = 3.0\n",
        "\n",
        "# B elemetns are constant and equal to BVAL\n",
        "BVAL = 5.0\n",
        "\n",
        "# tolerance used in floating point comparisons\n",
        "TOL = 0.001\n",
        "\n",
        "# Max dim for NDRange\n",
        "DIM = 2\n",
        "\n",
        "# number of times to do each multiplication\n",
        "COUNT = 1\n",
        "\n",
        "#  Function to compute the matrix product (sequential algorithm, dot prod)\n",
        "def seq_mat_mul_sdot(N, A, B, C):\n",
        "    for i in range(N):\n",
        "        for j in range(N):\n",
        "            tmp = 0.0\n",
        "            for k in range(N):\n",
        "                tmp += A[i*N+k] * B[k*N+j]\n",
        "            C[i*N+j] = tmp\n",
        "\n",
        "#  Function to compute errors of the product matrix\n",
        "def error(N, C):\n",
        "   cval = float(N) * AVAL * BVAL\n",
        "   errsq = 0.0\n",
        "   for i in range(N):\n",
        "       for j in range(N):\n",
        "            err = C[i*N+j] - cval\n",
        "            errsq += err * err\n",
        "   return errsq;\n",
        "\n",
        "\n",
        "# Function to analyze and output results\n",
        "def results(N, C, run_time):\n",
        "    mflops = 2.0 * N * N * N/(1000000.0* run_time)\n",
        "    print(run_time, \"seconds at\", mflops, \"MFLOPS\")\n",
        "    errsq = error(N, C)\n",
        "    if (errsq > TOL):\n",
        "        print(\"Errors in multiplication:\", errsq)\n",
        "\n",
        "C_elem_KernelSource = '''\n",
        "__kernel void mmul(\n",
        "    const int N,\n",
        "    __global float* A,\n",
        "    __global float* B,\n",
        "    __global float* C)\n",
        "{\n",
        "    int k;\n",
        "    int i = get_global_id(0);\n",
        "    int j = get_global_id(1);\n",
        "    float tmp = 0;\n",
        "    if ((i < N) && (j < N))\n",
        "    {\n",
        "        tmp = 0.0f;\n",
        "        for (k=0; k<N; k++)\n",
        "        {\n",
        "            tmp += A[i*N + k] * B[k*N + j];\n",
        "        }\n",
        "        C[i*N + j] = tmp;\n",
        "    }\n",
        "}\n",
        "'''\n",
        "\n",
        "# A[N][N], B[N][N], C[N][N]\n",
        "N = ORDER;\n",
        "\n",
        "# Number of elements in the matrix\n",
        "size = N * N\n",
        "\n",
        "\n",
        "# A matrix\n",
        "h_A = numpy.empty(size).astype(numpy.float32)\n",
        "h_A.fill(AVAL)\n",
        "\n",
        "# B matrix\n",
        "h_B = numpy.empty(size).astype(numpy.float32)\n",
        "h_B.fill(BVAL)\n",
        "\n",
        "# C matrix\n",
        "h_C = numpy.empty(size).astype(numpy.float32)\n",
        "\n",
        "print(\"\\n===== Sequential, matrix mult (dot prod), order\", ORDER, \"on host CPU ======\\n\")\n",
        "\n",
        "for i in range(COUNT):\n",
        "    h_C.fill(0.0)\n",
        "    start_time = time()\n",
        "\n",
        "    print(\"Skipping as this takes a long time to run!\")\n",
        "    #seq_mat_mul_sdot(N, h_A, h_B, h_C)\n",
        "\n",
        "    run_time = time() - start_time\n",
        "    #results(N, h_C, run_time)\n",
        "\n",
        "\n",
        "# Set up OpenCL\n",
        "context = cl.create_some_context()\n",
        "queue = cl.CommandQueue(context)\n",
        "\n",
        "# Reset host buffers - just to play it safe\n",
        "h_A = numpy.empty(size).astype(numpy.float32)\n",
        "h_A.fill(AVAL)\n",
        "h_B = numpy.empty(size).astype(numpy.float32)\n",
        "h_B.fill(BVAL)\n",
        "h_C = numpy.empty(size).astype(numpy.float32)\n",
        "\n",
        "# Create OpenCL buffers\n",
        "d_a = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_A)\n",
        "d_b = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_B)\n",
        "d_c = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_C.nbytes)\n",
        "\n",
        "program = cl.Program(context, C_elem_KernelSource).build()\n",
        "mmul = program.mmul\n",
        "mmul.set_scalar_arg_dtypes([numpy.int32, None, None, None])\n",
        "\n",
        "print(\"\\n===== OpenCL, matrix mult, C(i,j) per work item, order\", N, \"======\\n\")\n",
        "\n",
        "# Do the multiplication COUNT times\n",
        "for i in range(COUNT):\n",
        "    h_C.fill(0.0)\n",
        "    start_time = time()\n",
        "\n",
        "    globalrange = (N, N)\n",
        "    localrange = None\n",
        "\n",
        "    mmul(queue, globalrange, localrange, N, d_a, d_b, d_c)\n",
        "    queue.finish()\n",
        "\n",
        "    run_time = time() - start_time\n",
        "\n",
        "    cl.enqueue_copy(queue, h_C, d_c)\n",
        "    results(N, h_C, run_time)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "===== Sequential, matrix mult (dot prod), order 1024 on host CPU ======\n",
            "\n",
            "Skipping as this takes a long time to run!\n",
            "\n",
            "===== OpenCL, matrix mult, C(i,j) per work item, order 1024 ======\n",
            "\n",
            "0.09620928764343262 seconds at 22320.959863656055 MFLOPS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPtd3UHVO-lb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "5e25b0d5-13ea-4490-e5de-80484364942f"
      },
      "source": [
        "#\n",
        "# Matrix Multiplication Driver\n",
        "#\n",
        "# This is a driver program to test various ways of computing\n",
        "# the product:\n",
        "#                 C = A * B\n",
        "#\n",
        "# A and B are constant matrices, square and the order is\n",
        "# set as a constant, ORDER (see definitions.py). This is so\n",
        "# we can make a quick test of the multiplication result.\n",
        "#\n",
        "# History:   C++ version written by Tim Mattson, August 2010 \n",
        "#            Modified by Simon McIntosh-Smith, September 2011\n",
        "#            Modified by Tom Deakin and Simon McIntosh-Smith, October 2012\n",
        "#            Ported to Python by Tom Deakin, July 2013\n",
        "#\n",
        "\n",
        "from helper import *\n",
        "from definitions import *\n",
        "\n",
        "import pyopencl as cl\n",
        "import numpy\n",
        "from time import time\n",
        "\n",
        "# A[N][N], B[N][N], C[N][N]\n",
        "N = ORDER;\n",
        "\n",
        "\n",
        "# Number of elements in the matrix\n",
        "size = N * N\n",
        "\n",
        "\n",
        "# A matrix\n",
        "h_A = numpy.empty(size).astype(numpy.float32)\n",
        "h_A.fill(AVAL)\n",
        "\n",
        "# B matrix\n",
        "h_B = numpy.empty(size).astype(numpy.float32)\n",
        "h_B.fill(BVAL)\n",
        "\n",
        "# C matrix\n",
        "h_C = numpy.empty(size).astype(numpy.float32)\n",
        "\n",
        "print(\"\\n===== Sequential, matrix mult (dot prod), order\", ORDER, \"on host CPU ======\\n\")\n",
        "\n",
        "for i in range(COUNT):\n",
        "    h_C.fill(0.0)\n",
        "    start_time = time()\n",
        "\n",
        "    print(\"Skipping as this takes a long time to run!\")\n",
        "    #seq_mat_mul_sdot(N, h_A, h_B, h_C)\n",
        "\n",
        "    run_time = time() - start_time\n",
        "    #results(N, h_C, run_time)\n",
        "\n",
        "\n",
        "# Set up OpenCL\n",
        "context = cl.create_some_context()\n",
        "queue = cl.CommandQueue(context)\n",
        "\n",
        "# Reset host buffers - just to play it safe\n",
        "h_A = numpy.empty(size).astype(numpy.float32)\n",
        "h_A.fill(AVAL)\n",
        "h_B = numpy.empty(size).astype(numpy.float32)\n",
        "h_B.fill(BVAL)\n",
        "h_C = numpy.empty(size).astype(numpy.float32)\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------------------------\n",
        "# OpenCL matrix multiplication ... Naive\n",
        "#--------------------------------------------------------------------------------\n",
        "\n",
        "# Create OpenCL buffers\n",
        "d_a = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_A)\n",
        "d_b = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_B)\n",
        "d_c = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_C.nbytes)\n",
        "\n",
        "kernelsource = open(\"C_elem.cl\").read()\n",
        "program = cl.Program(context, kernelsource).build()\n",
        "mmul = program.mmul\n",
        "mmul.set_scalar_arg_dtypes([numpy.int32, None, None, None])\n",
        "print(\"\\n===== OpenCL, matrix mult, C(i,j) per work item, order\", N, \"======\\n\")\n",
        "\n",
        "# Do the multiplication COUNT times\n",
        "for i in range(COUNT):\n",
        "    h_C.fill(0.0)\n",
        "    start_time = time()\n",
        "\n",
        "    mmul(queue, (N, N), None, N, d_a, d_b, d_c)\n",
        "    queue.finish()\n",
        "\n",
        "    run_time = time() - start_time\n",
        "\n",
        "    cl.enqueue_copy(queue, h_C, d_c)\n",
        "    results(N, h_C, run_time)\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------------------------\n",
        "# OpenCL matrix multiplication ... blocked\n",
        "#--------------------------------------------------------------------------------\n",
        "\n",
        "kernelsource = open(\"C_block_form.cl\").read()\n",
        "program = cl.Program(context, kernelsource).build()\n",
        "mmul = program.mmul\n",
        "mmul.set_scalar_arg_dtypes([numpy.int32, None, None, None, None, None])\n",
        "print(\"\\n==== Parallel matrix mult (blocked), order {0} on device ======\\n\".format(N))\n",
        "# Do the multiplication COUNT times\n",
        "for i in range(COUNT):\n",
        "    h_C.fill(0.0)\n",
        "    start_time = time()\n",
        "\n",
        "    # Work-group computes a block of C. This size is also set\n",
        "    # in a #define inside the kernel function. Note this blocksize\n",
        "    # must evenly divide the matrix order\n",
        "    blocksize = 16\n",
        "\n",
        "    A_block = cl.LocalMemory(numpy.dtype(numpy.float32).itemsize * blocksize * blocksize)\n",
        "    B_block = cl.LocalMemory(numpy.dtype(numpy.float32).itemsize * blocksize * blocksize)\n",
        "    mmul(queue, (N,N), (blocksize,blocksize), N,\n",
        "        d_a, d_b, d_c, A_block, B_block)\n",
        "    queue.finish()\n",
        "\n",
        "    run_time = time() - start_time\n",
        "\n",
        "    cl.enqueue_copy(queue, h_C, d_c)\n",
        "    results(N, h_C, run_time)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "===== Sequential, matrix mult (dot prod), order 1024 on host CPU ======\n",
            "\n",
            "Skipping as this takes a long time to run!\n",
            "\n",
            "===== OpenCL, matrix mult, C(i,j) per work item, order 1024 ======\n",
            "\n",
            "0.09815645217895508 seconds at 21878.171025219923 MFLOPS\n",
            "\n",
            "==== Parallel matrix mult (blocked), order 1024 on device ======\n",
            "\n",
            "0.007661104202270508 seconds at 280309.9385286463 MFLOPS\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}